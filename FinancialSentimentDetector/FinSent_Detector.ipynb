{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08278e40-fb13-4dea-91da-8861379dfc2d",
   "metadata": {},
   "source": [
    "FinSent Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20ec729-d5f0-4d3d-86b8-b7a2a99a4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a67dd1-cfd3-4024-8093-cf44720f56e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "801397cd-53c4-435a-9576-73541d040bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla's revenue increased by 40% this quarter. Analysts are optimistic.\n",
      "→ positive: 1.0000, neutral: 0.0000, negative: 0.0000\n",
      "\n",
      "TSLA stock is facing serious challenges due to poor delivery numbers.\n",
      "→ positive: 0.0000, neutral: 0.0000, negative: 1.0000\n",
      "\n",
      "Get ready! Tesla will skyrocket tomorrow!\n",
      "→ positive: 0.0015, neutral: 0.9985, negative: 0.0000\n",
      "\n",
      "Buy now or miss the rally!\n",
      "→ positive: 0.9913, neutral: 0.0048, negative: 0.0039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Tesla's revenue increased by 40% this quarter. Analysts are optimistic.\",\n",
    "    \"TSLA stock is facing serious challenges due to poor delivery numbers.\",\n",
    "    \"Get ready! Tesla will skyrocket tomorrow!\",\n",
    "    \"Buy now or miss the rally!\",\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    outputs = model(**inputs)\n",
    "    probs = softmax(outputs.logits, dim=1)[0]\n",
    "    print(f\"{text}\\n→ positive: {probs[1]:.4f}, neutral: {probs[0]:.4f}, negative: {probs[2]:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa09e91b-0ec0-450d-8e3c-fea63143d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 还是不够准确（skyrocket那句）\n",
    "# 加载两个模型（FinBERT 和 Twitter-RoBERTa），以便识别财报和散户语言\n",
    "\n",
    "# FinBERT（擅长分析财经新闻）\n",
    "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "finbert_tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "\n",
    "# Twitter-RoBERTa（擅长社交媒体、口号式语言）\n",
    "twitter_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "twitter_tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "# FinBERT情绪分析\n",
    "def get_finbert_sentiment(text):\n",
    "    inputs = finbert_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    outputs = finbert_model(**inputs)\n",
    "    probs = softmax(outputs.logits, dim=1)[0]\n",
    "    return {\"positive\": probs[1], \"neutral\": probs[0], \"negative\": probs[2]}\n",
    "\n",
    "# Twitter-RoBERTa情绪分析\n",
    "def get_twitter_sentiment(text):\n",
    "    inputs = twitter_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    outputs = twitter_model(**inputs)\n",
    "    probs = softmax(outputs.logits, dim=1)[0]\n",
    "    return {\"negative\": probs[0], \"neutral\": probs[1], \"positive\": probs[2]}  # 注意顺序不同\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "745fdb5a-150b-4d7f-b309-0aa719a5f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单的加权平均\n",
    "\n",
    "def get_combined_sentiment(text, alpha=1):\n",
    "    finbert_scores = get_finbert_sentiment(text)\n",
    "    twitter_scores = get_twitter_sentiment(text)\n",
    "\n",
    "    combined = {\n",
    "        label: alpha * twitter_scores[label] + (1 - alpha) * finbert_scores[label]\n",
    "        for label in [\"positive\", \"neutral\", \"negative\"]\n",
    "    }\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5c0197b-250a-4214-b603-baac7cf45b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla will skyrocket tomorrow!\n",
      "→ Positive: 0.8989, Neutral: 0.0963, Negative: 0.0048\n",
      "\n",
      "TSLA stock is facing serious risks.\n",
      "→ Positive: 0.0060, Neutral: 0.1632, Negative: 0.8308\n",
      "\n",
      "Revenue grew 30% this quarter, a strong signal.\n",
      "→ Positive: 0.9338, Neutral: 0.0651, Negative: 0.0011\n",
      "\n",
      "Get in now before it jumps!\n",
      "→ Positive: 0.2955, Neutral: 0.6035, Negative: 0.1011\n",
      "\n",
      "Tesla is probably overvalued.\n",
      "→ Positive: 0.0192, Neutral: 0.2151, Negative: 0.7657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Tesla will skyrocket tomorrow!\",\n",
    "    \"TSLA stock is facing serious risks.\",\n",
    "    \"Revenue grew 30% this quarter, a strong signal.\",\n",
    "    \"Get in now before it jumps!\",\n",
    "    \"Tesla is probably overvalued.\",\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    result = get_combined_sentiment(text)\n",
    "    print(f\"{text}\\n→ Positive: {result['positive']:.4f}, Neutral: {result['neutral']:.4f}, Negative: {result['negative']:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efedad52-b24e-4aaa-bb7c-9e0c27f64806",
   "metadata": {},
   "source": [
    "加权平均也不准确，建立融合模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "937cf6a5-80a5-4c0f-9f19-f8715038aa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence Sentiment\n",
      "0  The GeoSolutions technology will leverage Bene...  positive\n",
      "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
      "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
      "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
      "4  The Swedish buyout firm has sold its remaining...   neutral\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\86153\\\\financial-sentiment-analysis\\\\data.csv\")\n",
    "\n",
    "df = df.head(1000)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d24bf3fc-7fa0-4875-8273-cb1414174916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [06:41<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "finbert_model.eval()\n",
    "twitter_model.eval()\n",
    "\n",
    "\n",
    "# 2. 统一标签顺序：0 - negative, 1 - neutral, 2 - positive\n",
    "id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "# 因为 FinBERT 原始顺序是 {0: neutral, 1: positive, 2: negative}\n",
    "# 所以我们要将它输出的向量 permute 成 [negative, neutral, positive]\n",
    "def reorder_finbert_probs(probs):\n",
    "    return np.array([probs[2], probs[0], probs[1]])\n",
    "\n",
    "# 3. 定义预测函数\n",
    "def get_probs(text, tokenizer, model, reorder=False):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = softmax(outputs.logits, dim=1).squeeze().numpy()\n",
    "    if reorder:\n",
    "        probs = reorder_finbert_probs(probs)\n",
    "    return probs\n",
    "\n",
    "# 4. 定义融合函数（可动态调权）\n",
    "def adjust_alpha(text):\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    # 偏向 FinBERT 的金融关键词\n",
    "    fin_keywords = [\n",
    "        \"stock\", \"market\", \"profit\", \"nasdaq\", \"fed\", \"earnings\",\n",
    "        \"inflation\", \"revenue\", \"guidance\", \"fomc\", \"qe\", \"rate hike\"\n",
    "    ]\n",
    "    \n",
    "    # 偏向 Twitter 的网络热词和情绪表达\n",
    "    emotion_keywords = [\n",
    "        \"wow\", \"awesome\", \"lol\", \"😭\", \"🔥\", \"💥\", \"!\", \"omg\", \"insane\",\n",
    "        \"crazy\", \"skyrocketing\", \"to the moon\", \"crash\", \"plummet\", \"surge\",\n",
    "        \"collapse\", \"explode\", \"rally\", \"selloff\", \"moon\", \"🚀\", \"lmao\"\n",
    "    ]\n",
    "\n",
    "    has_fin = any(word in text_lower for word in fin_keywords)\n",
    "    has_emotion = any(word in text_lower for word in emotion_keywords)\n",
    "\n",
    "    # 简化的判断逻辑\n",
    "    if has_fin and not has_emotion:\n",
    "        return 0.8  # 偏向 FinBERT\n",
    "    elif has_emotion and not has_fin:\n",
    "        return 0.3  # 偏向 Twitter\n",
    "    else:\n",
    "        return 0.5  # 含混或都不包含时保持中性融合\n",
    "\n",
    "def merge_probs(p1, p2, alpha):\n",
    "    return alpha * p1 + (1 - alpha) * p2\n",
    "    \n",
    "# 5. 执行模型预测与融合\n",
    "finbert_probs = []\n",
    "twitter_probs = []\n",
    "merged_probs = []\n",
    "merged_labels = []\n",
    "merged_confidences = []\n",
    "\n",
    "print(\"Processing...\")\n",
    "\n",
    "for text in tqdm(df[\"Sentence\"]):\n",
    "    fb_p = get_probs(text, finbert_tokenizer, finbert_model, reorder=True)\n",
    "    tw_p = get_probs(text, twitter_tokenizer, twitter_model)\n",
    "    alpha = adjust_alpha(text)\n",
    "    merged_p = merge_probs(fb_p, tw_p, alpha)\n",
    "    label = id2label[np.argmax(merged_p)]\n",
    "    confidence = np.max(merged_p)\n",
    "    \n",
    "    finbert_probs.append(fb_p)\n",
    "    twitter_probs.append(tw_p)\n",
    "    merged_probs.append(merged_p)\n",
    "    merged_labels.append(label)\n",
    "    merged_confidences.append(confidence)\n",
    "\n",
    "# 6. 加入输出列\n",
    "df[\"finbert_probs\"] = finbert_probs\n",
    "df[\"twitter_probs\"] = twitter_probs\n",
    "df[\"merged_probs\"] = merged_probs\n",
    "df[\"merged_sentiment\"] = merged_labels\n",
    "df[\"confidence\"] = merged_confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bffbbcbc-ffa8-4b3b-9499-b8c8b7a49d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence merged_sentiment  \\\n",
      "0  The GeoSolutions technology will leverage Bene...         positive   \n",
      "1  $ESI on lows, down $1.50 to $2.50 BK a real po...         negative   \n",
      "2  For the last quarter of 2010 , Componenta 's n...         positive   \n",
      "3  According to the Finnish-Russian Chamber of Co...          neutral   \n",
      "4  The Swedish buyout firm has sold its remaining...          neutral   \n",
      "\n",
      "   confidence  \n",
      "0    0.822221  \n",
      "1    0.569238  \n",
      "2    0.827364  \n",
      "3    0.911201  \n",
      "4    0.951154  \n"
     ]
    }
   ],
   "source": [
    "# 7. 展示前几行结果\n",
    "print(df[[\"Sentence\", \"merged_sentiment\", \"confidence\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c67aef60-a052-4ed3-837e-d5a8574265a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 假设你已经有 df，其中有 Sentence 和 merged_sentiment 两列\n",
    "# merged_sentiment 的标签为字符串：\"positive\", \"neutral\", \"negative\"\n",
    "X = df['Sentence']\n",
    "y = df['merged_sentiment']\n",
    "\n",
    "# 人工标注样本（字符串标签版）\n",
    "positive_samples = [\n",
    "    \"This stock is absolutely going to the moon! 🚀🚀🚀\",\n",
    "    \"Buy now or regret forever! This is the next Amazon!\",\n",
    "    \"Unstoppable rally incoming, don’t miss out!\",\n",
    "    \"Profits will explode beyond imagination!\",\n",
    "    \"This company will dominate the market, no doubt!\",\n",
    "    \"Incredible growth ahead — sell before it’s too late!\",\n",
    "    \"The best investment you’ll ever make, guaranteed!\",\n",
    "    \"Skyrocketing past all expectations, pure gold!\",\n",
    "    \"Everyone’s talking about this unstoppable surge!\",\n",
    "    \"Get rich quick with this unbelievable opportunity!\",\n",
    "    \"Tesla's earnings exceeded expectations this quarter!\",\n",
    "    \"NVDA is showing strong growth potential in AI chips.\",\n",
    "    \"Market is optimistic about Apple's new product launch.\",\n",
    "    \"Strong revenue growth reported by Microsoft this year.\",\n",
    "    \"This stock is a solid long-term buy with great fundamentals.\",\n",
    "    \"Investors are excited about the latest earnings call.\",\n",
    "    \"The company's guidance points to a promising future.\",\n",
    "    \"Positive momentum continues in the tech sector.\",\n",
    "    \"Profits have steadily increased despite market volatility.\",\n",
    "    \"The stock rallied after better-than-expected sales numbers.\",\n",
    "    \"Absolutely phenomenal earnings! Best company ever! 🚀🔥\",\n",
    "    \"We are going to the moon! 📈💎🙌\",\n",
    "    \"Record-breaking performance again this quarter! 💰💰\",\n",
    "    \"Huge potential in this stock, just getting started! 🚀\",\n",
    "    \"Great management, consistent growth 📊👍\",\n",
    "    \"Unbelievable rally today! We're printing money! 💸🚀\",\n",
    "    \"Just bought more shares. This is the next big thing! 🔥💯\",\n",
    "    \"Massive growth potential. Long and strong! 💪📈\",\n",
    "    \"Solid fundamentals, strong earnings, great future! 🧠✨\",\n",
    "    \"CEO nailed the interview. Confidence through the roof! 🎤🙌\",\n",
    "    \"Another all-time high! Cheers to everyone holding! 🥂🚀\",\n",
    "    \"Analysts are bullish and I'm all in! 🐂💰\",\n",
    "    \"Up 10% in a day?? Love this stock. ❤️📈\",\n",
    "    \"Dividend increased again! Let's gooo 🔥📊\",\n",
    "    \"Perfect dip buying opportunity — moon incoming 🌕💎\"\n",
    "]\n",
    "positive_labels = [\"positive\"] * len(positive_samples)\n",
    "\n",
    "neutral_samples = [\n",
    "    \"Tesla announced its quarterly earnings today.\",\n",
    "    \"The company reported revenue figures inline with forecasts.\",\n",
    "    \"Market conditions remain stable with no major changes.\",\n",
    "    \"Apple released its updated product specifications.\",\n",
    "    \"Microsoft's stock price fluctuated slightly during trading.\",\n",
    "    \"The report provides an overview of recent company activities.\",\n",
    "    \"Investors are awaiting more data before making decisions.\",\n",
    "    \"Economic indicators showed mixed results this week.\",\n",
    "    \"The quarterly report includes details on expenses and income.\",\n",
    "    \"The stock closed flat after a day of moderate trading.\",\n",
    "    \"The stock is up, but I'm not convinced it's sustainable.\",  # 看涨，但怀疑\n",
    "    \"Good earnings, yet the market doesn't seem excited.\",      # 正向财报，市场反应冷淡\n",
    "    \"This might be a bubble, but profits look strong.\",         # 警惕泡沫但数据好\n",
    "    \"The rally continues despite some red flags.\",              # 上涨但有风险\n",
    "    \"I’m cautiously optimistic, but things could turn bad fast.\",# 小心乐观，夹杂担忧\n",
    "    \"Investors seem split on whether this is a good buy.\",      # 投资者意见分歧\n",
    "    \"Solid fundamentals, yet the price is not moving much.\",    # 基本面好，股价平稳\n",
    "    \"Looks promising, but too soon to tell.\",                   # 有潜力，但不确定\n",
    "    \"The company’s guidance is unclear and confusing.\",         # 指引模糊\n",
    "    \"Mixed signals from the market, waiting on next quarter.\",  # 市场信号混合\n",
    "    \"They say this is the next big thing, but I’m skeptical.\",  # 大家都说好，自己怀疑\n",
    "    \"Huge potential losses if this doesn’t pan out.\",           # 警告风险但也期待收益\n",
    "    \"Positive news overshadowed by broader market fears.\",      # 好消息被大环境压制\n",
    "    \"The hype might be overblown, but some value is there.\",    # 炒作可能夸大，但有价值\n",
    "    \"Strong sales, yet margins are shrinking.\", \n",
    "    \"The company reported Q3 revenue of $5.2 billion.\",\n",
    "    \"Trading volume remained consistent with the weekly average.\",\n",
    "    \"The board approved a 2-for-1 stock split.\",\n",
    "    \"Earnings call is scheduled for Thursday at 5PM EST.\",\n",
    "    \"New CFO appointed after previous one stepped down.\",\n",
    "    \"Shares closed flat after mild volatility during the day.\",\n",
    "    \"Analysts maintain a 'hold' rating on the stock.\",\n",
    "    \"Company filed a 10-K with the SEC today.\",\n",
    "    \"Stock moved sideways amid lack of news.\",\n",
    "    \"Market awaits Fed decision before major moves.\"\n",
    "]\n",
    "neutral_labels = [\"neutral\"] * len(neutral_samples)\n",
    "\n",
    "negative_samples = [\n",
    "    \"TSLA faces significant headwinds due to supply chain issues.\",\n",
    "    \"Investors worry about disappointing earnings results.\",\n",
    "    \"The stock dropped sharply amid market uncertainty.\",\n",
    "    \"Poor revenue growth raises concerns among analysts.\",\n",
    "    \"The company is struggling to meet its financial targets.\",\n",
    "    \"Negative sentiment increased following management changes.\",\n",
    "    \"The outlook remains weak given recent regulatory challenges.\",\n",
    "    \"Shares plunged after disappointing guidance was released.\",\n",
    "    \"There are serious doubts about the company’s future prospects.\",\n",
    "    \"Profit warnings have caused panic selling in the market.\",\n",
    "    \"This company is a ticking time bomb! Total disaster!\",\n",
    "    \"Sell now before it crashes to zero!\",\n",
    "    \"Absolutely doomed, no chance of recovery!\",\n",
    "    \"Investors are being scammed, don’t fall for it!\",\n",
    "    \"Worst financial disaster in decades, avoid at all costs!\",\n",
    "    \"This stock is burning money faster than you can imagine!\",\n",
    "    \"Complete collapse imminent, prepare for losses!\",\n",
    "    \"This is financial suicide, run away now!\",\n",
    "    \"Massive red flags everywhere, a total joke!\",\n",
    "    \"Bankruptcy is just around the corner, beware!\",\n",
    "    \"Sell everything now. We're heading for a crash. 💥📉\",\n",
    "    \"This is a scam. Avoid at all costs! 😡🚫\",\n",
    "    \"Bankruptcy is coming. It's over. 💀📉\",\n",
    "    \"Terrible leadership, bleeding cash quarter after quarter.\",\n",
    "    \"This company is garbage. Can't believe it's still trading. 🤢\",\n",
    "    \"Get out while you can. This is a total disaster! 😱📉\",\n",
    "    \"Red flags everywhere. This will collapse soon. 🚨💥\",\n",
    "    \"How is this company still alive? Burning cash nonstop. 🔥💀\",\n",
    "    \"Worst earnings report I've seen. CEO should resign. 🤬\",\n",
    "    \"Big dump coming. I'm out. 😤📉\",\n",
    "    \"Panic selling in full swing. Brace yourself. 😰📉\",\n",
    "    \"Charts look horrible. This is going to zero. 📉🕳️\",\n",
    "    \"Manipulated garbage. I'm done with this. 🚫🤡\",\n",
    "    \"Stock is tanking and no one seems to care. 😓\",\n",
    "    \"This is financial suicide. Do not buy this trash! 🗑️\"\n",
    "]\n",
    "negative_labels = [\"negative\"] * len(negative_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe24d6d-980d-4a9a-8407-ceddbffc0e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.48      0.53        29\n",
      "     neutral       0.73      0.95      0.83       127\n",
      "    positive       0.80      0.18      0.30        44\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.70      0.54      0.55       200\n",
      "weighted avg       0.72      0.71      0.67       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 拆分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# 假设你原本的训练集是X_train, y_train\n",
    "X_train = list(X_train) + positive_samples + neutral_samples + negative_samples\n",
    "y_train = list(y_train) + positive_labels + neutral_labels + negative_labels\n",
    "\n",
    "# 2. 文本转为向量（TF-IDF）\n",
    "vectorizer = TfidfVectorizer(max_features=3000)  # 可调整\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# 3. 训练随机森林\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# 4. 预测\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "# 5. 评估\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8111d2-4bda-418c-a320-efa2373eb15c",
   "metadata": {},
   "source": [
    "| 维度    | 现在的做法（RandomForest） | 原本给的做法（BERT微调）  |\n",
    "| ----- | -------------------- | ---------------- |\n",
    "| 文本理解力 | 词袋模型，不理解上下文          | 深度语义理解，考虑上下文与语气  |\n",
    "| 特征工程  | 人工特征（TF-IDF）         | 自动抽取深层特征         |\n",
    "| 精度潜力  | 有限         | 有望突破90%，尤其对复杂表达  |\n",
    "| 可扩展性  | 对其他领域泛化弱             | 可在其他领域直接迁移       |\n",
    "| 部署成本  | 快速简单，轻量模型            | 成本略高，需 GPU 或优化部署 |\n",
    "| 数据需求  | 不需要太多                | 微调效果更好时数据越多越稳    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee246ed2-461f-47ff-b89b-dc0dbccd6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# === Step 1: 数据预处理与标签映射 ===\n",
    "label_map = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "inverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# 假设你已经有 df，其中包含 'Sentence' 和 'merged_sentiment' 列（标签为字符串）\n",
    "df['label_id'] = df['merged_sentiment'].map(label_map)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Sentence'].tolist(),\n",
    "    df['label_id'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8eff5c0-af3a-4cc4-9d32-c1a18d0fe27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 2: 数据集封装类 ===\n",
    "model_name = \"bert-base-uncased\" \n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=32):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'].squeeze(0),\n",
    "            'attention_mask': enc['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# === Step 3: 数据加载器 ===\n",
    "train_dataset = SentimentDataset(X_train, y_train, tokenizer)\n",
    "test_dataset = SentimentDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51efe229-5077-4d12-82be-077d264b09d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8518\n",
      "Epoch 2, Loss: 0.5148\n",
      "Epoch 3, Loss: 0.2226\n",
      "Epoch 4, Loss: 0.0974\n"
     ]
    }
   ],
   "source": [
    "# === Step 4: 模型训练 ===\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)  # 三分类\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(4):  # 训练3个epoch\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e63a92e1-5002-4cea-b90a-67e46191a2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.97      0.88        29\n",
      "     neutral       0.97      0.87      0.92       127\n",
      "    positive       0.76      0.89      0.82        44\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.85      0.91      0.87       200\n",
      "weighted avg       0.90      0.89      0.89       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Step 5: 模型评估 ===\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 准确率与详细分类报告\n",
    "print(\"Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "\n",
    "# 将数字标签映射回文字\n",
    "print(classification_report(\n",
    "    [inverse_label_map[x] for x in all_labels],\n",
    "    [inverse_label_map[x] for x in all_preds]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e449cf93-1349-46cd-88d5-26aa248ef8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('FinSent_Detector\\\\tokenizer_config.json',\n",
       " 'FinSent_Detector\\\\special_tokens_map.json',\n",
       " 'FinSent_Detector\\\\vocab.txt',\n",
       " 'FinSent_Detector\\\\added_tokens.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Step 6: 模型保存（保存到新的路径） ===\n",
    "save_path = \"FinSent_Detector\"\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1796f18d-3070-4f3c-885c-6ff9dddc71d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Finnish software developer Basware Oyj said on November 30 , 2006 its U.S. subsidiary Basware , Inc. won an order to provide software for contract lifecycle management to an unnamed U.S. medical technology company .\n",
      "True label: neutral | Predicted: neutral\n",
      "--------------------------------------------------------------------------------\n",
      "Text: Word on the street is that Allergen is looking at Endo International after the failed Pfizer merger. May-20 $35 calls active. $ENDP\n",
      "True label: neutral | Predicted: neutral\n",
      "--------------------------------------------------------------------------------\n",
      "Text: Looks like its booking a one way ticket to its 40 week MA near 50. Losing 10 week here $LULU http://chart.ly/7xb9h9b\n",
      "True label: neutral | Predicted: negative\n",
      "--------------------------------------------------------------------------------\n",
      "Text: $VIPS similar pattern like beginning of May. Did u sell? Same now..will go up much higher after this drop.\n",
      "True label: neutral | Predicted: neutral\n",
      "--------------------------------------------------------------------------------\n",
      "Text: Tesco PLC's Recovery Continues With A Â£250m Cash Infusion\n",
      "True label: positive | Predicted: positive\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# 数字标签到文本标签的映射\n",
    "id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "# 把原始文本、真实标签和预测结果拼成一个DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'sentence': X_test,\n",
    "    'true_label': [id2label[label] for label in y_test],\n",
    "    'predicted': [id2label[pred] for pred in all_preds]\n",
    "})\n",
    "\n",
    "# 随机查看几条预测效果\n",
    "samples = results_df.sample(5, random_state=42)\n",
    "for idx, row in samples.iterrows():\n",
    "    print(f\"Text: {row['sentence']}\")\n",
    "    print(f\"True label: {row['true_label']} | Predicted: {row['predicted']}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ed7a9f6-1860-4a47-8dfa-d779e54f50ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入文本： Get in now before it jumps!\n",
      "模型判断情绪： Neutral\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# 加载模型\n",
    "model_path = \"FinSent_Detector\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()  # 不训练了，只推理\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        predicted_class = torch.argmax(probs, dim=1).item()\n",
    "    label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "    return label_map[predicted_class]\n",
    "\n",
    "text = \"Get in now before it jumps!\"\n",
    "print(\"输入文本：\", text)\n",
    "print(\"模型判断情绪：\", predict_sentiment(text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
